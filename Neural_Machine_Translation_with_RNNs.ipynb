{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nimendra-ag/Deep-Learning-NLP-for-Sentiment-analysis-Translation/blob/main/Neural_Machine_Translation_with_RNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZ-4rFnXb-AB"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf### models\n",
        "import numpy as np### math computations\n",
        "import matplotlib.pyplot as plt### plotting bar chart\n",
        "import sklearn### machine learning library\n",
        "from sklearn.metrics import confusion_matrix, roc_curve### metrics\n",
        "import seaborn as sns### visualizations\n",
        "import datetime\n",
        "import pathlib\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import time\n",
        "from numpy import random\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import (Dense,Flatten,SimpleRNN,InputLayer,Conv1D,Bidirectional,GRU,LSTM,BatchNormalization,Dropout,Input, Embedding,TextVectorization)\n",
        "from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from tensorboard.plugins import projector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiFpjnGSd5mZ"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQkQSOtyd95X"
      },
      "source": [
        "## Data Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Na1NhUXdBti",
        "outputId": "d08567a1-1c39-4160-eaa9-e24e333983a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-03-14 11:52:50--  https://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7943074 (7.6M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip’\n",
            "\n",
            "fra-eng.zip         100%[===================>]   7.57M  16.3MB/s    in 0.5s    \n",
            "\n",
            "2025-03-14 11:52:50 (16.3 MB/s) - ‘fra-eng.zip’ saved [7943074/7943074]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.manythings.org/anki/fra-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfLbDeBbdCJK",
        "outputId": "006d7e37-cc97-4e8a-c75e-f81160c6b866"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/fra-eng.zip\n",
            "  inflating: /content/dataset/_about.txt  \n",
            "  inflating: /content/dataset/fra.txt  \n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/fra-eng.zip\" -d \"/content/dataset/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ5oTdC4eElF"
      },
      "source": [
        "## Kaggle Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDhBs_7mfkjg"
      },
      "source": [
        "If you want to go with the kaggle data set you can use it. But if you use the other data set don't run these cells which are related to the kaggle dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDA6NqTodJVB",
        "outputId": "c1bad8fa-55f6-47d8-ea38-200756cc0efc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.7.4 / client 1.6.17)\n",
            "Dataset URL: https://www.kaggle.com/datasets/dhruvildave/en-fr-translation-dataset\n",
            "License(s): ODbL-1.0\n",
            "Downloading en-fr-translation-dataset.zip to /content\n",
            "100% 2.54G/2.54G [00:30<00:00, 122MB/s] \n",
            "100% 2.54G/2.54G [00:30<00:00, 90.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "# !pip install -q kaggle\n",
        "# !mkdir ~/.kaggle\n",
        "# !cp kaggle.json ~/.kaggle/\n",
        "# !chmod 600 /root/.kaggle/kaggle.json\n",
        "# !kaggle datasets download -d dhruvildave/en-fr-translation-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne8DbxqAeLY5",
        "outputId": "92becdee-dbea-4ce1-afda-7f9e15898f0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/en-fr-translation-dataset.zip\n",
            "  inflating: /content/dataset/en-fr.csv  \n"
          ]
        }
      ],
      "source": [
        "# !unzip \"/content/en-fr-translation-dataset.zip\" -d \"/content/dataset/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvDAFe37eWeg"
      },
      "outputs": [],
      "source": [
        "# dataset = tf.data.experimental.CsvDataset(\n",
        "#   \"/content/dataset/en-fr.csv\",\n",
        "#   [\n",
        "#     tf.string,\n",
        "#     tf.string\n",
        "#   ],\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB1acAy6eZM1"
      },
      "source": [
        "## Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzDWAAdyeYNQ"
      },
      "outputs": [],
      "source": [
        "text_dataset=tf.data.TextLineDataset(\"/content/dataset/fra.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "items = []\n",
        "for line in text_dataset:\n",
        "  items.append(line)\n",
        "\n",
        "len(items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhEPLPF3_7HR",
        "outputId": "6507896f-98c6-460b-a1b9-c5961ddffd0c"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "232736"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random_items = random.sample(items, int(232736*0.4))"
      ],
      "metadata": {
        "id": "vqXXVL0cAwYP"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lengths = np.empty(232736)\n",
        "i = 0\n",
        "for line in text_dataset.take(232736):\n",
        "  lengths[i] = len(tf.strings.split(line, ' '))\n",
        "  i = i + 1\n",
        "lengths.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmGzJCSLAeyv",
        "outputId": "3a9ba7cd-1de3-4609-96c2-92a49ac51471"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.628669393647737"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lengths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw9C7vWw8zSc",
        "outputId": "2428f947-5472-4cc6-cc63-9ca5e67c12a9"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 11.,  10.,  12., ..., 107., 106., 119.])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "e8NCWEpkgXR_",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# for line in text_dataset:\n",
        "#   print(line.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iterater = iter(text_dataset)\n",
        "first_value = next(iterater)\n",
        "print(first_value)\n",
        "print(type(first_value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxqQSnR5klO6",
        "outputId": "eb23472d-f4d6-4794-b7c5-2db3a77a4cd5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'Go.\\tVa !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)', shape=(), dtype=string)\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "DR1j8hKSekLC"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE=20000\n",
        "ENGLISH_SEQUENCE_LENGTH=64\n",
        "FRENCH_SEQUENCE_LENGTH=64\n",
        "EMBEDDING_DIM=300\n",
        "BATCH_SIZE=64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gHZdACIzero7"
      },
      "outputs": [],
      "source": [
        "english_vectorize_layer=TextVectorization(\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=ENGLISH_SEQUENCE_LENGTH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "YPR6cjipuySz"
      },
      "outputs": [],
      "source": [
        "french_vectorize_layer=TextVectorization(\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=FRENCH_SEQUENCE_LENGTH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in text_dataset.take(1):\n",
        "  print(i.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4X6soJKnsvVv",
        "outputId": "686a9ce9-c907-467d-b223-ec0934badbb9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'Go.\\tVa !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in text_dataset.take(1):\n",
        "  splitted_text=tf.strings.split(i,'\\t')\n",
        "  print(splitted_text[0], splitted_text[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xVYOjqiItrn4",
        "outputId": "ac3f2f5f-8eb5-43dc-adc1-b8329d4f57f7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'Go.', shape=(), dtype=string) tf.Tensor(b'Va !', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jnhr2bJNy8K5"
      },
      "outputs": [],
      "source": [
        "def selector(input_text):\n",
        "  split_text=tf.strings.split(input_text,'\\t')\n",
        "  return {'input_1':split_text[0:1],'input_2':'starttoken '+split_text[1:2]},split_text[1:2]+' endtoken'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "tVZed1qLziLf"
      },
      "outputs": [],
      "source": [
        "split_dataset=text_dataset.map(selector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lsqLN772eZ4",
        "outputId": "48f22d93-f121-4e22-fa30-40d0e06335e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Va !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Va ! endtoken'], dtype=object)>)\n",
            "[b'Go.']\n",
            "[b'starttoken Va !']\n",
            "[b'Va ! endtoken']\n"
          ]
        }
      ],
      "source": [
        "for i in split_dataset.take(1):\n",
        "  print(i)\n",
        "  print(i[0]['input_1'].numpy())\n",
        "  print(i[0]['input_2'].numpy())\n",
        "  print(i[1].numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "5OdkrhWK2LDA"
      },
      "outputs": [],
      "source": [
        "def separator(input_text):\n",
        "  split_text=tf.strings.split(input_text, '\\t')\n",
        "  return split_text[0:1], 'starttoken ' + split_text[1:2] + ' endtoken'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "TeqGKe0G2m-v"
      },
      "outputs": [],
      "source": [
        "init_dataset=text_dataset.map(separator)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in init_dataset.take(1):\n",
        "  print(i)\n",
        "  print(i[0])\n",
        "  print(i[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bneqnaLlyRhf",
        "outputId": "13ed2ce7-435b-45bc-c4f6-33287974d9ff"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Va ! endtoken'], dtype=object)>)\n",
            "tf.Tensor([b'Go.'], shape=(1,), dtype=string)\n",
            "tf.Tensor([b'starttoken Va ! endtoken'], shape=(1,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "T08plaA34pUA"
      },
      "outputs": [],
      "source": [
        "english_training_data=init_dataset.map(lambda x,y:x)  #input x, y and output x\n",
        "english_vectorize_layer.adapt(english_training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "_cSa9ATR5kqF"
      },
      "outputs": [],
      "source": [
        "french_training_data=init_dataset.map(lambda x,y:y) #input x, y and output y\n",
        "french_vectorize_layer.adapt(french_training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-rWtX2W5TQT",
        "outputId": "501d7473-5b40-4b9d-f2d0-9220930a5e82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16952\n",
            "20000\n"
          ]
        }
      ],
      "source": [
        "print(len(english_vectorize_layer.get_vocabulary()))\n",
        "print(len(french_vectorize_layer.get_vocabulary()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "b96Rxgu657-4"
      },
      "outputs": [],
      "source": [
        "def vectorizer(inputs, output):\n",
        "  return {'input_1':english_vectorize_layer(inputs['input_1']),\n",
        "          'input_2':french_vectorize_layer(inputs['input_2'])},french_vectorize_layer(output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in split_dataset.take(1):\n",
        "  print(english_vectorize_layer(i[0]['input_1']))\n",
        "  print(english_vectorize_layer(i[0]['input_2']))\n",
        "  print(french_vectorize_layer(i[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNAbUsVNdlRg",
        "outputId": "b64f15fc-3180-4706-c189-6e82caf46684"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[45  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]], shape=(1, 64), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]], shape=(1, 64), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[104   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]], shape=(1, 64), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXdKWUul_FCt",
        "outputId": "2ba0e487-0f7b-49d0-a04e-cf093f09b076"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=({'input_1': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'input_2': TensorSpec(shape=(None,), dtype=tf.string, name=None)}, TensorSpec(shape=(None,), dtype=tf.string, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ],
      "source": [
        "split_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "H2sxfNVi_GZH"
      },
      "outputs": [],
      "source": [
        "dataset=split_dataset.map(vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYR-73aIC53b",
        "outputId": "c63205fd-0d63-44b2-e37b-72447a44c932"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Va !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Va ! endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Marche.'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Marche. endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken En route !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'En route ! endtoken'], dtype=object)>)\n"
          ]
        }
      ],
      "source": [
        "for i in split_dataset.take(3):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_vectorize_layer.get_vocabulary()[45]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ZUDW3L_ymolG",
        "outputId": "1a133ff6-3836-4fa1-fd95-3a40aec25f02"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'go'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "french_vectorize_layer.get_vocabulary()[104]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dYQemS2vnCW3",
        "outputId": "1283778f-76bc-4ea2-ad5e-09046c339fe2"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'va'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvAQpixuJsMO",
        "outputId": "06de09bf-11da-4e97-ce71-a6caf00f80c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[45,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>, 'input_2': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[  2, 104,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>}, <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[104,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>)\n"
          ]
        }
      ],
      "source": [
        "for i in dataset.take(1):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17epy_9kKUKE",
        "outputId": "919b660b-b6d6-4f00-8191-d5946dda5773"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=({'input_1': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, None), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "2RDJeZJHMK10"
      },
      "outputs": [],
      "source": [
        "dataset=dataset.shuffle(2048).unbatch().batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gac_c64HoSje",
        "outputId": "430ecb82-9e5d-477a-ef67-764b686a7dd7"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=({'input_1': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, None), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82hevKV328-Q",
        "outputId": "f39339ca-cda9-4214-a07c-8c4059e95fe5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3125"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ],
      "source": [
        "NUM_BATCHES = int(200000/BATCH_SIZE)\n",
        "NUM_BATCHES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "xeC37SF-3Lnv"
      },
      "outputs": [],
      "source": [
        "train_dataset=dataset.take(int(0.9*NUM_BATCHES))\n",
        "val_dataset=dataset.skip(int(0.9*NUM_BATCHES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "OcNnj1vZ3LOQ",
        "outputId": "fb13ed8e-5abd-45b8-cd8f-104e8ba58290"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.take_op._TakeDataset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>tensorflow.python.data.ops.take_op._TakeDataset</b><br/>def __init__(input_dataset, count, name=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/take_op.py</a>A `Dataset` containing the first `count` elements from its input.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 27);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ],
      "source": [
        "type(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFxWZOAa3p33",
        "outputId": "a343b307-f14b-496e-a075-b146ef91cfc4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TakeDataset element_spec=({'input_1': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, None), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFMt-BILpiPo",
        "outputId": "40cd7192-37e1-4e95-caa2-b5760476ad6b"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_SkipDataset element_spec=({'input_1': TensorSpec(shape=(None, None), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, None), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzqkQG5m2uJY"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAPFuRCGMkRz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkdHPE49IFxzvTCAzP/bS2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}